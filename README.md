<div align="center"><img src="./docs/hands-for-bots-cover.png" alt="[â€¢_â€¢] Hands for Bots" style="max-width: 100%;width: 700px;margin: auto;display: block;"></div>

<div align="right">

[![pt-BR](https://img.shields.io/badge/pt-BR-white)](./docs/pt-br/README.md)
[![en-US](https://img.shields.io/badge/en-US-white)](./README.md)

</div>

<div align="center">

![Hands for Bots](https://img.shields.io/badge/[â€¢__â€¢]-Hands_for_Bots-purple?style=social) &nbsp; ![Conversational User Interface](https://img.shields.io/badge/ðŸ—£-Conversational_UI-purple?style=social) &nbsp; ![Front-end](https://img.shields.io/badge/ðŸ“º-Front_end-purple?style=social)

[![JavaScript](https://img.shields.io/badge/javascript-%23323330.svg?style=for-the-badge&logo=javascript&logoColor=%23F7DF1E)](https://www.javascript.com) &nbsp; [![MIT License](https://img.shields.io/badge/license-MIT-green?style=for-the-badge&color=%23750014)](./LICENSE.md) &nbsp; [![GitHub Repo](https://img.shields.io/badge/github-%23323330.svg?style=for-the-badge&logo=github&logoColor=%23FFFFFF)](https://github.com/alexlana/handsforbots)

ðŸ˜© [![GitHub contributors](https://img.shields.io/github/contributors/alexlana/handsforbots)](https://GitHub.com/alexlana/handsforbots/graphs/contributors/) ðŸ˜¥

</div>

For now the **Hands for Bots** is a hybrid conversational UI library for browsers. This means that graphic, sound and other inputs and outputs can be present. It gives to chatbots / assistants the hability to interact with GUI and other user interfaces through functions calling, and receive inputs from diferent UIs.

Hands for Bots uses a modular archtecture based on plugins to grant a high level of flexibility, modularity and extensibility to build chatbot's front end. Event triggers and listeners connects the core to plugins. To call external functions, we should call the function directly, this not depends on the internal architecture.

**Important:** this library don't give to assistants the hability to "view" the screen and do things in your computer.

## Table of contents

- [Get started](./docs/en-us/getstarted.md)
- [Development](./docs/en-us/development.md)
- [Core](./docs/en-us/core.md)
  - [Backend](./docs/en-us/core/backend.md)
	- [RASA](./docs/en-us/core/backend/rasa.md)
	- [OpenAI](./docs/en-us/core/backend/openai.md)
  - [Input](./docs/en-us/core/input.md)
	- [Text](./docs/en-us/core/input/text.md)
	- [Voice](./docs/en-us/core/input/voice.md)
	- [Poke](./docs/en-us/core/input/poke.md)
  - [Output](./docs/en-us/core/output.md)
	- [Bots Commands](./docs/en-us/core/output/botscommands.md)
	- [Text](./docs/en-us/core/output/text.md)
	- [Voice](./docs/en-us/core/output/voice.md)
- [Plugins](./docs/en-us/plugins.md)
  - [GUIDed](./docs/en-us/plugins/guided.md)
- [Events](./docs/en-us/events.md)



## Acknowledgment

Grateful for the authors of [these third-party libraries and frameworks](./NOTICE.md)

## Roadmap

There is an intention to improve the quality of the Hands for Bots' code and develop gesture capture plugins, as well as ready-to-use features for virtual reality and conversational applications, perhaps even in wearable technologies. That's a long way off, but let's get it.

