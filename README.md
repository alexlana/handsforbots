# [â€¢_â€¢] Hands for Bots

<div align="center">
<br />

![Hands for Bots](https://img.shields.io/badge/[â€¢__â€¢]-Hands_for_Bots-purple?style=social) &nbsp; ![Conversational User Interface](https://img.shields.io/badge/ðŸ—£-Conversational_UI-purple?style=social) &nbsp; ![Front-end](https://img.shields.io/badge/ðŸ“º-Front_end-purple?style=social)

![JavaScript](https://img.shields.io/badge/javascript-%23323330.svg?style=for-the-badge&logo=javascript&logoColor=%23F7DF1E) &nbsp; ![Docker](https://img.shields.io/badge/docker-%23323330.svg?style=for-the-badge&logo=docker&logoColor=%230db7ed)

ðŸ˜© [![GitHub contributors](https://img.shields.io/github/contributors/alexlana/handsforbots)](https://GitHub.com/alexlana/handsforbots/graphs/contributors/) ðŸ˜¥

</div>

For now the **Hands for Bots** is a conversational UI framework for browsers. It gives to chatbots / assistants the hability to interact with GUI and other user interfaces through functions calling, and receive inputs from the UIs. 

The archtecture is a not strict Ports and Adapters (Hexagonal Architecture). Event triggers and listeners connects the core to plugins / adapters. To call external functions, we should call the function directly, this not depends on the internal architecture.

**Important:** this framework don't give to assistants the hability to "view" the screen and do things in your computer.

## Table of contents

- [Get started](./docs/getstarted.md)
- [Development](./docs/development.md)

## Acknowledgment

Grateful for the authors of [these third-party libraries](./NOTICE.md)

## Roadmap

There is an intention to improve the quality of the Hands for Bots code and develop functionalities ready-to-use in virtual reality and conversational applications, perhaps even in wearable technologies.

<hr>

[![Licence](https://img.shields.io/github/license/Ileriayo/markdown-badges?style=for-the-badge)](./LICENSE.md)

